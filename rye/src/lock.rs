use std::collections::{HashMap, HashSet};
use std::io::{BufWriter, Write};
use std::path::Path;
use std::process::Command;
use std::sync::Arc;
use std::{fmt, fs};

use anyhow::{anyhow, bail, Context, Error};
use once_cell::sync::Lazy;
use pep508_rs::Requirement;
use regex::Regex;
use tempfile::NamedTempFile;
use url::Url;

use crate::bootstrap::{ensure_self_venv, link_pip_tools};
use crate::pyproject::{normalize_package_name, DependencyKind, PyProject, Workspace};
use crate::utils::CommandOutput;

static FILE_EDITABLE_RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"^-e (file://.*?)\s*$").unwrap());
static REQUIREMENTS_HEADER: &str = "\
# generated by rye\n\
# use `rye lock` or `rye sync` to update this lockfile\
";

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub enum LockMode {
    Production,
    Dev,
}

impl fmt::Display for LockMode {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(
            f,
            "{}",
            match self {
                LockMode::Production => "production",
                LockMode::Dev => "dev",
            }
        )
    }
}

/// Controls how locking should work.
#[derive(Debug, Clone, Default)]
pub struct LockOptions {
    /// Instruct all packages to update.
    pub update_all: bool,
    /// Update specific packages.
    pub update: Vec<String>,
    /// Pick pre-release versions.
    pub pre: bool,
}

/// Creates lockfiles for all projects in the workspace.
pub fn update_workspace_lockfile(
    workspace: &Arc<Workspace>,
    lock_mode: LockMode,
    lockfile: &Path,
    output: CommandOutput,
    lock_options: &LockOptions,
) -> Result<(), Error> {
    if output != CommandOutput::Quiet {
        eprintln!("Generating {} lockfile: {}", lock_mode, lockfile.display());
    }

    let mut req_file = NamedTempFile::new()?;
    let mut local_req_file = NamedTempFile::new()?;

    let mut local_projects = HashMap::new();
    let mut projects = Vec::new();
    for pyproject_result in workspace.iter_projects() {
        let pyproject = pyproject_result?;
        let rel_url = make_relative_url(&pyproject.root_path(), &workspace.path())?;
        writeln!(local_req_file, "-e {}", rel_url)?;
        if let Some(name) = pyproject.normalized_name() {
            local_projects.insert(name, rel_url);
        }
        projects.push(pyproject);
    }

    for pyproject in &projects {
        dump_dependencies(
            pyproject,
            &local_projects,
            req_file.as_file_mut(),
            DependencyKind::Normal,
        )?;
        if lock_mode == LockMode::Dev {
            dump_dependencies(
                pyproject,
                &local_projects,
                req_file.as_file_mut(),
                DependencyKind::Dev,
            )?;
        }
    }

    let exclusions = find_exclusions(&projects)?;
    generate_lockfile(
        output,
        &workspace.path(),
        req_file.path(),
        lockfile,
        lock_options,
        &exclusions,
        &[],
    )?;
    generate_lockfile(
        output,
        &workspace.path(),
        local_req_file.path(),
        lockfile,
        lock_options,
        &exclusions,
        &["--pip-args=--no-deps"],
    )?;

    Ok(())
}

fn find_exclusions(projects: &[PyProject]) -> Result<HashSet<Requirement>, Error> {
    let mut rv = HashSet::new();
    for project in projects {
        for dep in project.iter_dependencies(DependencyKind::Excluded) {
            rv.insert(dep.expand(|name: &str| {
                if name == "PROJECT_ROOT" {
                    Some(project.workspace_path().to_string_lossy().to_string())
                } else {
                    std::env::var(name).ok()
                }
            })?);
        }
    }
    Ok(rv)
}

fn dump_dependencies(
    pyproject: &PyProject,
    local_projects: &HashMap<String, String>,
    out: &mut fs::File,
    dep_kind: DependencyKind,
) -> Result<(), Error> {
    for dep in pyproject.iter_dependencies(dep_kind) {
        if let Ok(expanded_dep) = dep.expand(|_| {
            // we actually do not care what it expands to much, for as long
            // as the end result parses
            Some("VARIABLE".into())
        }) {
            if let Some(path) = local_projects.get(&normalize_package_name(&expanded_dep.name)) {
                // if there are extras and we have a local dependency, we just write it
                // out again for pip-compile to pick up the extras.
                // XXX: this drops the marker, but pip-compile already has other
                // problems with markers too: https://github.com/jazzband/pip-tools/issues/826
                if let Some(ref extras) = expanded_dep.extras {
                    writeln!(out, "-e {}[{}]", path, extras.join(","))?;
                }
                continue;
            }
        }
        writeln!(out, "{}", dep)?;
    }
    Ok(())
}

/// Updates the lockfile of the current project.
pub fn update_single_project_lockfile(
    pyproject: &PyProject,
    lock_mode: LockMode,
    lockfile: &Path,
    output: CommandOutput,
    lock_options: &LockOptions,
) -> Result<(), Error> {
    if output != CommandOutput::Quiet {
        eprintln!("Generating {} lockfile: {}", lock_mode, lockfile.display());
    }

    let mut req_file = NamedTempFile::new()?;
    writeln!(
        req_file,
        "-e {}",
        make_relative_url(&pyproject.root_path(), &pyproject.workspace_path())?
    )?;
    for dep in pyproject.iter_dependencies(DependencyKind::Normal) {
        writeln!(req_file, "{}", dep)?;
    }
    if lock_mode == LockMode::Dev {
        for dep in pyproject.iter_dependencies(DependencyKind::Dev) {
            writeln!(req_file, "{}", dep)?;
        }
    }

    let exclusions = find_exclusions(std::slice::from_ref(pyproject))?;
    generate_lockfile(
        output,
        &pyproject.workspace_path(),
        req_file.path(),
        lockfile,
        lock_options,
        &exclusions,
        &[],
    )?;

    Ok(())
}

fn generate_lockfile(
    output: CommandOutput,
    workspace_path: &Path,
    requirements_file_in: &Path,
    lockfile: &Path,
    lock_options: &LockOptions,
    exclusions: &HashSet<Requirement>,
    extra_args: &[&str],
) -> Result<(), Error> {
    let self_venv = ensure_self_venv(output)?;
    let scratch = tempfile::tempdir()?;
    let requirements_file = scratch.path().join("requirements.txt");
    if lockfile.is_file() {
        fs::copy(lockfile, &requirements_file)?;
    } else {
        fs::write(&requirements_file, b"")?;
    }

    link_pip_tools(&self_venv, scratch.path()).context("failed to link pip-tools internals")?;

    let mut cmd = Command::new(workspace_path.join(".venv/bin/python"));
    cmd.arg("-c")
        .arg("from piptools.scripts.compile import cli; cli()")
        .arg("--resolver=backtracking")
        .arg("--no-annotate")
        .arg("--strip-extras")
        .arg("--allow-unsafe")
        .arg("--no-header")
        .arg("-o")
        .arg(&requirements_file)
        .arg(requirements_file_in)
        .env("PYTHONWARNINGS", "ignore")
        .env("PYTHONPATH", scratch.path());
    if output == CommandOutput::Verbose {
        cmd.arg("--verbose");
    } else {
        cmd.arg("-q");
    }
    for pkg in &lock_options.update {
        cmd.arg("--upgrade-package");
        cmd.arg(pkg);
    }
    if lock_options.update_all {
        cmd.arg("--upgrade");
    }
    if lock_options.pre {
        cmd.arg("--pre");
    }
    cmd.args(extra_args);
    let status = cmd.status().context("unable to run pip-compile")?;
    if !status.success() {
        bail!("failed to generate lockfile");
    };

    finalize_lockfile(&requirements_file, lockfile, workspace_path, exclusions)?;

    Ok(())
}

fn finalize_lockfile(
    generated: &Path,
    out: &Path,
    workspace_root: &Path,
    exclusions: &HashSet<Requirement>,
) -> Result<(), Error> {
    let mut rv = BufWriter::new(fs::File::create(out)?);
    writeln!(rv, "{}", REQUIREMENTS_HEADER)?;
    for line in fs::read_to_string(generated)?.lines() {
        if let Some(m) = FILE_EDITABLE_RE.captures(line) {
            let url = Url::parse(&m[1]).context("invalid editable URL generated")?;
            if url.scheme() == "file" {
                let rel_url = make_relative_url(Path::new(url.path()), workspace_root)?;
                writeln!(rv, "-e {}", rel_url)?;
                continue;
            }
        } else if let Ok(ref req) = line.trim().parse::<Requirement>() {
            // TODO: this does not evaluate markers
            if exclusions.iter().any(|x| {
                normalize_package_name(&x.name) == normalize_package_name(&req.name)
                    && (x.version_or_url.is_none() || x.version_or_url == req.version_or_url)
            }) {
                // skip exclusions
                writeln!(rv, "# excluded {}", line)?;
                continue;
            }
        }
        writeln!(rv, "{}", line)?;
    }
    Ok(())
}

fn make_relative_url(path: &Path, base: &Path) -> Result<String, Error> {
    // TODO: consider using ${PROJECT_ROOT} here which is what pdm does or make-req prints
    let rv = pathdiff::diff_paths(path, base).ok_or_else(|| {
        anyhow!(
            "unable to create relative path from {} to {}",
            base.display(),
            path.display()
        )
    })?;
    if rv == Path::new("") {
        Ok("file:.".into())
    } else {
        // XXX: there might be a better way to do this, but this appears to be enough
        // to make this work for now.
        let mut buf = String::new();
        for chunk in url::form_urlencoded::byte_serialize(rv.to_string_lossy().as_bytes()) {
            buf.push_str(&chunk.replace('+', "%20").replace("%2F", "/"));
        }
        Ok(format!("file:{}", buf))
    }
}

#[test]
fn test_make_relativec_url() {
    assert_eq!(
        make_relative_url(Path::new("foo/bar/baz blah"), Path::new("foo")).unwrap(),
        "file:bar/baz%20blah"
    );
    assert_eq!(
        make_relative_url(Path::new("/foo"), Path::new("/foo")).unwrap(),
        "file:."
    );
}
